---
title: "Machine Learning-R"
author: "Thomas Laurent"
date: "29/08/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
myVariableNames=c("Comptes","Duree_credit","Historique_credit","Objet_credit","Montant_credit","Epargne","Anciennete_emploi","Taux_effort","Situation_familiale","Garanties","Anciennete_domicile","Biens","Age","Autres_credits","Statut_domicile","Nb_credits","Type_emploi","Nb_pers_charge","Telephone","Etranger","Cible")
# 
# credit=read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data",h=FALSE,col.names=myVariableNames)

credit=read.table("http://blogperso.univ-rennes1.fr/stephane.tuffery/public/german.txt",h=FALSE,col.names=myVariableNames)

#OId des observations
credit$Cle=seq(1,nrow(credit))
credit$Etranger=NULL
```

```{r}
#Variable transformation
credit$Cible[credit$Cible==1]=0
credit$Cible[credit$Cible==2]=1

credit$Cible=factor(credit$Cible)

varquali=c("Comptes","Epargne","Historique_credit","Objet_credit","Situation_familiale","Garanties","Biens","Autres_credits","Statut_domicile","Type_emploi","Anciennete_emploi","Telephone","Nb_pers_charge")

for (v in varquali) {credit[[v]]=factor(credit[[v]])}

varquali=c("Duree_credit","Montant_credit","Taux_effort","Anciennete_domicile","Age","Nb_credits")

vars=-grep('Cle',names(credit))
```

```{r}
grep("Nb",names(credit))
```

```{r}
#Echantillonage
s=sort(sample(nrow(credit),nrow(credit)*2/3,replace=F))

table(credit[s,]$Cible)
```

#Exploration des donnees

```{r,fig.height=12,fig.width=12}
summary(credit[,vars])

library(Hmisc)
hist.data.frame(credit[,1:16])
```

```{r}
library(lattice)
histogram(~Duree_credit | Cible,data=credit,type="percent",col="grey",
          breaks=10)
histogram(~Montant_credit | Cible,data=credit,type="percent",col="grey",
          breaks=10)
histogram(~Age | Cible,data=credit,type="percent",col="grey",
          breaks=10)

by(credit[c("Age","Duree_credit","Montant_credit")],list(Cible=credit$Cible),
   summary)
```

```{r}
#Test de kruskal-wallis
sqrt(kruskal.test(credit$Age~credit$Cible)$statistic/sum(!is.na(credit$Age)))

#Discretisation
q=quantile(credit$Age,seq(0,1,by=0.1))
q[1]=q[1]-1
qage=cut(credit$Age,q)
tab=table(qage,credit$Cible)
prop.table(tab,1)

barplot(prop.table(tab,1)[,2],ylim=c(0,0.5),las=3,
        main="Age",ylab="Taux impayes",density=0)

#Age
Age=cut(credit$Age,c(0,25,Inf))
tab=table(Age,credit$Cible)
q=unique(quantile(credit$Duree_credit,seq(0,1,by=0.05)))

#Duree du credit
Duree_credit=cut(credit$Duree_credit,c(0,15,36,Inf))
tab=table(Duree_credit,credit$Cible)
prop.table(tab,1)

#Montant du credit
Montant_credit=cut(credit$Montant_credit,c(0,4000,Inf))
tab=table(Montant_credit,credit$Cible)
prop.table(tab,1)
```

```{r}
#Liaison des variables explocatives avec variable a expliquer
npred=-grep('(Cle|Cible|Duree_credit|Montant_credit|Age)',names(credit))

credit2=credit[,npred]
credit2$Age=Age
credit2$Duree_credit=Duree_credit
credit2$Montant_credit=Montant_credit

cramer=matrix(NA,ncol(credit2),3)
for (i in (1:ncol(credit2))){
  cramer[i,1]=names(credit2[i])
  cramer[i,2]=sqrt(chisq.test(table(credit2[,i],credit$Cible))$statistic/(length(credit2[,i])))
  cramer[i,3]=chisq.test(credit2[,i],credit$Cible)$p.value
}
colnames(cramer)=c("variable","V de Cramer","p-value chi-2")
vcramer=cramer[order(cramer[,2],decreasing=T),]

par(mar=c(8,4,4,0))
barplot(as.numeric(vcramer[,2]),
        col=gray(0:nrow(vcramer)/nrow(vcramer)),
        names.arg=vcramer[,1],ylab='V de Cramer',
        ylim=c(0,0.35),cex.names=0.8,las=3)
```

```{r}
#Recodage
ct=function(x){
  cat("\n",names(credit)[x],"\n")
  cbind(prop.table(table(credit[,x],credit$Cible),1),
        table(credit[,x]))
}

for (i in (1:ncol(credit))){
  if (!(names(credit[i])) %in% c("Cle","Cible","Duree_credit","Montant_credit",
                                 "Age"))
  {
    print(ct(i))
  }
}

library(car)
credit2$Comptes=recode(credit2$Comptes,"'A14'='Pas de compte';
                       'A11'='CC < 0 euros';'A12'='CC [0-200 euros[';
                       'A13'='CC > 200 euros'")

credit2$Historique_credit=recode(credit2$Historique_credit,
                                 "'A30'='Impayes passes';
                                 'A31'='Impaye en cours dans autre banque';c('A32','A33')='Pas de credits ou en cours sans retard';
                                 'A34'='Credits passes sans retard'")

credit2$Objet_credit=recode(credit2$Objet_credit,
                            "'A40'='Voiture neuve';'A41'='Voiture occasion';c('A42','A44','A45')='Interieur';'A43'='Video - HIFI';
                            c('A46','A48')='Etudes';
                            'A47'='Vacances';'A49'='Business';
                            else='Autres'")

credit2$Epargne=recode(credit2$Epargne,"
                       'A65'='Sans epargne';c('A61','A62')='< 500 euros';
                       c('A63','A64')='> 500 euros'")

credit2$Anciennete_emploi=recode(credit2$Anciennete_emploi,
                                 "c('A71','A72')='Sans emploi ou < 1 an';
                                 'A73'='entre 1 et 4 ans';
                                 c('A74','A75')='depuis au moins 4 ans'")

credit2$Situation_familiale=recode(credit2$Situation_familiale,
                                   "'A91'='Homme divorce/separe';
                                   'A92'='Femme divorcee/separee/mariee';
                                   c('A93','A94')='Homme celibataire/marie/veuf';'A95'='Femme celibataire'")

credit2$Garanties=recode(credit2$Garanties,
                         "'A103'='Avec garant';
                         else='Sans garant'")

credit2$Biens=recode(credit2$Biens,
                     "'A121'='Immobilier';
                     'A124'='Aucun bien';else='Non immobilier'")

credit2$Autres_credits=recode(credit2$Autres_credits,"'A143'='Aucun credit exterieur';
                              else='Credit exterieurs'")

credit2$Statut_domicile=recode(credit2$Statut_domicile,"'A152'='Proprietaire';
                              else='Non proprietaire'")
```

```{r}
#Tableau croise
library(gmodels)
CrossTable(credit$Comptes,credit$Cible,prop.chisq=F,chisq=TRUE,format="SAS")

summary(credit2)
```

```{r}
#Echantillon d'apprentissage et de test
set.seed(123)
id=(1:1000)[which(runif(1000)<0.66)]
train=credit2[id,]
test=credit2[-id,]
```

```{r}
#Liaison entre les variables explicatives
library(questionr)
cramer=matrix(NA,ncol(credit2),ncol(credit2))
for (i in (1:ncol(credit2))){
  for (j in (1:ncol(credit2)))
  {
    cramer[i,j]=cramer.v(table(credit2[,i],credit2[,j]))
  }
}

colnames(cramer)=colnames(credit2)
rownames(cramer)=colnames(credit2)

library(corrplot)
old=par(no.readonly = TRUE)
par(omi=c(0.4,0.4,0.4,0.4))
corrplot(cramer,type="upper",tl.srt=45,tl.col="black",diag=F,addCoef.col="black",
         addCoefasPercent=T)
par(old)
```

#Discretisation automatique

```{r}
library(pROC)
#Creation de la fonction decoup
decoup=function(base,x,y,h=0,k=0,pAUC=0,nbmod=3,calcul=1,
                algo="Nelder-Mead",graphe=0){
  #Renommage des variables
  attach(base)
  Xt=x
  Yt=y
  detach(base)
  
  #Traitement specifique des valeurs manquantes
  X=Xt[is.na(Xt)==0]
  Y=Yt[is.na(Xt)==0]
  
  seuils=as.vector(quantile(X,seq(0,1,length=(nbmod+1))))[2:nbmod]
  
  fitauc=function(s){
    s2=c(-Inf,unique(s),Inf)
    qX=cut(X,s2)
    tab=table(qX,Y)
    logit=glm(Y~qX,family=binomial(link="logit"))
    qXn=predict(logit,newdata=base[is.na(Xt)==0,],type="response")
    resultat=auc(Y,qXn,partial.auc=c(1,pAUC),partial.auc.correct=FALSE)*
      (1-sum((table(qX)/length(X))^2))/(1-(1-h)*(sum((table(qX)/length(X))^2)))*
      ((1-(1-k)*sum((prop.table(tab,1)[,2])^2)))/(1-sum((prop.table(tab,1)[,2])^2))
    return(-resultat)
  }
  
  #Application du decoupage
  Applical=function(){
    sf=unique(c(-Inf,est$par,Inf))
    qX=cut(Xt,sf)
    tab=table(qX,Yt,useNA="ifany")
    cat("\n","Resultat du decoupage :","\n")
    cat("\n","Seuils   %Negat.  %  Posit. #  +  #    %  #","\n")
    print(cbind(prop.table(tab,1)*100,tab[,2],table(qX,useNA="ifany"),table(qX,useNA="ifany")*100/length(Xt)))
    cat("\n","Indicateur de convergence (0=convergence optimisation)","\n")
    cat(est$convergence) #verifier qu'on obtient 0
    cat("\n","AUC (partielle) maximisee :","\n")
    cat(-est$value)
    cat("\n","Homogeneite des classes (0 <- faible ...  forte-> 1) :","\n")
    cat(1-sum((table(addNA(qX))/length(Xt))^2))
    return(qX)
  }
  
  #Calcul aire sous la courbe ROC
  Gini=function(t){
    cat("\n","AUC avant decoupage","\n")
    logit=glm(Y~X,family=binomial(link="logit"))
    g1=auc(Y,predict(logit,newdata=base[is.na(Xt)==0,],type="response"))
    cat(g1)
    cat("\n","AUC apres decoupage :","\n")
    logit=glm(Yt~t,family=binomial(link="logit"))
    g2=auc(Yt,predict(logit,newdata=base,type="response"))
    cat(g2)
    cat("\n","% Evolution AUC avant/apres decoupage :","\n")
    cat(100*(g2-g1)/g1)
    cat("\n")
  }
  
  #recherche des seuils optimaux a partir des valeurs initiales precedentes calcul=1
  #ou utilisation de bornes prescrites (calcul=0)
  if (calcul==1) {est=optim(seuils,fitauc,method=algo)}
  else {est=list() ; est$par=bornes ; est$convergence=0; est$value=0}
  
  cat("\n","____________________________________________________","\n")
  cat("\n","Discretisation de",substitute(x),"en",nbmod,"classes (algorithme ",algo,") \n")
  cat("\n","____________________________________________________","\n") 
  
  qX1=Applical()
  Gini(qX1)
  
  #courbe de densite
  if (graphe==1){
    layout(matrix(c(1,2)),heights=c(3,1))
    par(mar=c(2,3,2,1))
    base0=X[Y==0]
    base1=X[Y==1]
    xlim1=range(c(base0,base1))
    ylim1=c(0,max(max(density(base0)$y),max(density(base1)$y)))
    plot(density(base0),main=" ",col="blue",ylab=paste("Densite de ",
                                                       deparse(substitute(x))),
         xlim=xlim1,ylim=ylim1,lwd=2)
    lines(density(base1),col="red",lty=3,lwd=2)
    legend("topright",c(paste(deparse(substitute(y)),"=0"),
                        paste(deparse(substitute(y))," =1")),
           lty=c(1,3),col=c("blue","red"),lwd=2)
    abline(v=est$par,lty=2)
    texte=c("Chi de Kruskal-Wallis = \n \n",
            round(kruskal.test(X~Y)$statistic,digits=3))
    text(xlim1[2]*0.8,ylim1[2]*0.5,texte,cex=0.75)
    plot(X~Y,horizontal=TRUE,xlab=deparse(substitute(y)),
         col=c("blue","red"))
  }
  
  #fin de la fonction de discretisation automatique
  
}

rm(Age)
rm(Duree_credit)
rm(Montant_credit)

decoup(credit,Duree_credit,Cible,nbmod=3,h=1,k=0,pAUC=0.8,algo="BFGS",graphe=1)
```

```{r}
for (i in (2:5)) {
  decoup(credit,Age,Cible,nbmod=i,h=0,k=0,
pAUC=0.8,graphe=1)
}

for (i in (2:5)) {
  decoup(credit,Duree_credit,Cible,nbmod=i,h=0,k=0,
pAUC=0.8,graphe=1)
}
```

#Regression logistique

```{r}
#formule
predicteurs=grep('(Cle|Cible)',names(credit2))
formule=as.formula(paste("y ~ ",
                         paste(names(credit2),collapse="+")))

#Train and test
set.seed(1234)
train_id=sample(nrow(credit),nrow(credit)*2/3,replace=F)

train=credit2[train_id,]
test=credit2[-train_id,]

train_cible=credit$Cible[train_id]
test_cible=credit$Cible[-train_id]
```

```{r}
#Model
logit=glm(train_cible~1,data=train,family=binomial(link="logit"))

selection=step(logit,direction="forward",trace=TRUE,
               k=log(nrow(train)),scope=list(upper=formule))

selection
```

```{r}
#Calcul AUC du modele obtenu
selection=glm(train_cible~Comptes+Duree_credit+Garanties+Autres_credits+Age,
              data=train,family=binomial(link="logit"))

train.ascbic=predict(selection,newdata=train,type="response")
valid.ascbic=predict(selection,newdata=test,type="response")

library(ROCR)
pred=prediction(train.ascbic,train_cible,label.ordering=c(0,1))
performance(pred,"auc")@y.values[[1]]

pred=prediction(valid.ascbic,test_cible,label.ordering=c(0,1))
performance(pred,"auc")@y.values[[1]]
```

```{r}
#Selection via AIC
selection=step(logit,direction="forward",trace=TRUE,
               k=2,scope=list(upper=formule))

#Calcul AUC du modele obtenu
selection=glm(train_cible~Comptes+Duree_credit+Objet_credit+
                Historique_credit+Epargne+Garanties+Age+
                Autres_credits+Taux_effort+Montant_credit+
                Statut_domicile+Anciennete_emploi,
              data=train,family=binomial(link="logit"))

train.ascbic=predict(selection,newdata=train,type="response")
valid.ascbic=predict(selection,newdata=test,type="response")

library(ROCR)
pred=prediction(train.ascbic,train_cible,label.ordering=c(0,1))
performance(pred,"auc")@y.values[[1]]

pred=prediction(valid.ascbic,test_cible,label.ordering=c(0,1))
performance(pred,"auc")@y.values[[1]]

summary(selection)
```

```{r}
selection=step(logit,direction="forward",trace=TRUE,k=2,
               scope=list(upper=~Comptes+Duree_credit+Historique_credit+
                            Epargne+Garanties+Age+Autres_credits+
                            Taux_effort+Montant_credit+Statut_domicile+
                            Anciennete_emploi))
```

```{r}
#Selection descendante
logit=glm(train_cible~.,data=train,family = binomial)
slection=step(logit,direction="backward",trace=TRUE,k=log(nrow(train)))
```

```{r}
#Leaps and bounds
x=data.frame(model.matrix(~.,data=train))

library(leaps)
y=as.numeric(train_cible)

y[y==1]=0
y[y==2]=1
selec=leaps(x,y,method="Cp",nbest=1,strictly.compatible = F)
plot(selec$size-1,selec$Cp,xlab="#predicteurs",ylab="Cp")

# selec=leaps(x,y,method="adjr2",nbest=1,strictly.compatible=F)
# which(selec$adjr2==max(selec$adjr2))

#Selection du meilleur modele
best.model=selec$which[((selec$Cp==min(selec$Cp))),]
formule=as.formula(paste("y ~",
                         paste(colnames(x)[best.model],collapse="+")))
z=cbind(x,y)
logit=glm(formule,data=z,binomial(link="logit"))
summary(logit)

#Application a l'echantillon test
xt=data.frame(model.matrix(~.,data=test))
prob=predict(logit,newdata=xt,type="response")

pred=prediction(prob,test_cible,label.ordering=c(0,1))
performance(pred,"auc")@y.values[[1]]

selec=leaps(x,y,method="Cp",nbest=10,strictly.compatible=F)
nmodel=nrow(selec$which)
aucfw=matrix(NA,nmodel,3)
models=matrix(NA,nmodel,ncol(selec$which)+1)

for (i in 1:nmodel){
  best.model=selec$which[i,]
  formule=as.formula(paste("y ~",
                           paste(colnames(x)[best.model],
                                 collapse="+")))
  logit=glm(formule,data=z,family=binomial(link="logit"))
  prob=predict(logit,newdata=xt,type="response")
  pred=prediction(prob,test_cible,label.ordering=c(0,1))
  performance(pred,"auc")@y.values[[1]]
  aucfw[i,1]=selec$size[i]-1
  aucfw[i,2]=performance(pred,"auc")@y.values[[1]]
  models[i,1:ncol(selec$which)]=selec$which[i,1:ncol(selec$which)]
  models[i,ncol(selec$which)+1]=performance(pred,"auc")@y.values[[1]]
  aucfw[i,3]=selec$Cp[i]
}

colnames(aucfw)=c("taille","AUC","Cp")
selglob=aucfw[order(aucfw[,2],decreasing=T),]
selglob

```

```{r}
#Selection globale en utilisant regsubsets
fw=regsubsets(train_cible~.,data=train,nbest=1,nvmax=16,really.big=T)
selec=summary(fw)

plot(fw,scale="bic")

plot(apply(selec$which,1,sum)-1,selec$bic,xlab="# predicteurs",ylab="BIC")

#1000 meilleurs modeles
# fw=regsubsets(train_cible~.,data=train,nbest=1000,nvmax=16,really.big=T)
# selec=summary(fw)
# 
# plot(fw,scale="bic")
# 
# plot(apply(selec$which,1,sum)-1,selec$bic,xlab="# predicteurs",ylab="BIC")
```

```{r}
#Fonction pour tester les 1000 modeles
fw=regsubsets(train_cible~.,data=train,nbest=20,nvmax=16,really.big=T)
selec=summary(fw)
x=data.frame(model.matrix(~.,data=train))
y=as.numeric(train_cible)

y[y==1]=0
y[y==2]=1
z=cbind(x,y)
xt=data.frame(model.matrix(~.,data=test))
nmodel=nrow(selec$which)
aucfw=matrix(NA,nmodel,3)
models=matrix(NA,nmodel,ncol(selec$which)+1)

for (i in 1:nmodel){
  best.model=selec$which[i,]
  formule=as.formula(paste("y ~",
                           paste(colnames(x)[best.model],
                                 collapse="+")))
  logit=glm(formule,data=z,family=binomial(link="logit"))
  prob=predict(logit,newdata=xt,type="response")
  pred=prediction(prob,test_cible,label.ordering=c(0,1))
  performance(pred,"auc")@y.values[[1]]
  aucfw[i,1]=apply(selec$which,1,sum)[i]-1
  aucfw[i,2]=performance(pred,"auc")@y.values[[1]]
  models[i,1:ncol(selec$which)]=selec$which[i,1:ncol(selec$which)]
  models[i,ncol(selec$which)+1]=performance(pred,"auc")@y.values[[1]]
  aucfw[i,3]=selec$bic[i]
}

colnames(aucfw)=c("taille","AUC","BIC")
selglob=aucfw[order(aucfw[,2],na.last=NA,decreasing=T),]

head(selglob)

```

```{r,fig.height=5,fig.width=5}
#Recherche des predicteurs maximisant l'aire sous la courbe ROC
colnames(models)=c(names(x),"AUC")
ensmodels=as.data.frame(models)
library(rpart)
cart1=rpart(AUC~.,data=ensmodels,method="anova",parms=list(split="gini"),
           control=list(maxdepth=3))

plot(cart1)
text(cart1)
```

```{r}
#Utilisation de random forest pour l'importance des variables
library(randomForest)
set.seed(235)
rf=randomForest(AUC~.,data=ensmodels,importance=TRUE,ntree=500,
                mtry=6,replace=T,keep.forest=T,nodesize=5)
varImpPlot(rf,cex=0.5)
```

```{r,eval=FALSE}
library(dplyr)
train=train %>% 
  mutate(Cible=train_cible)

test=test %>% 
  mutate(Cible=test_cible)

#Variable predictives
vars=-grep('Cible',names(train))
varx=names(train)[vars]

CombiRegR=function(apprent,validat,varY,varX,p)
{
  y=apprent[,varY] # variable a expliquer
  cible=validat[,varY] #variable a predire
  size=length(varX) # nombre total de variables
  combi=combn(size,p) # combinaison de variables
  predi=matrix(" ",dim(combi)[2],p)
  
  f=function(i)
  {
    #Selection des predicteurs
    s=combi[,i] #ie combinaison de variables
    predicteurs=varX[s]
    
    #ecriture de la formule aves les predicteurs selectionnes
    if (p>1){
      formule=as.formula(paste("y ~",
                               paste(names(apprent[,predicteurs]),collapse="+")))
    } else{
      formule=as.formula(paste("y ~",predicteurs))
    }
    #ajustement du modele logit
    logit=glm(formule,data=apprent,family=binomial(link="logit"))
    #application du modele logit a l'echantillon de test
    scores=predict(logit,newdata=validat,type="response")
    pred=prediction(scores,cible,label.ordering = c(0,1))
    return(list(auc=performance(pred,"auc")@y.values[[1]],predi=predicteurs))
    } #fin de la fonction a vectoriser
  
  cr=matrix(unlist(Vectorize(f)(seq(1,dim(combi)[2]))),
            ncol=p+1,byrow=T)
  
}

system.time(cr<-CombiRegR(apprent=train,validat = test,varY="Cible",varX=varx,p=7))

#affichage des combinaisons par Gini decroissante
resultat=data.frame(cr)
colnames(resultat)=c("AUC",paste("V",1:(ncol(resultat)-1),sep=""))
resultat=resultat[order(resultat$AUC,decreasing=T),]
head(resultat)
```

##Regroupement definitif des modalites

```{r}
#Regroupement

credit2=credit
credit2$Comptes=recode(credit2$Comptes,"'A14'='Pas de compte';
                       'A11'='CC < 0 euros' ; 'A12'='CC [0-200 euros[';
                       'A13'='CC > 200 euros'")
credit2$Historique_credit=recode(credit2$Historique_credit,
                                 "c('A30','A31')='Credit en impaye';
                                 c('A32','A33')='Pas de credits ou en cours sans retard';
                                 'A34'='Credits passes sans retard'")
credit2$Objet_credit=recode(credit2$Objet_credit,
                            "'A40'='Voiture neuve';'A41'='Voiture occasion';
                            c('A42','A43','A44','A45')='Interieur';
                            c('A46','A48','A49','A410')='Etudes-business-Autres';
                            'A47'='Vacances'")
credit2$Epargne=recode(credit2$Epargne,
                       "c('A63','A64','A65')='Pas epargne ou > 500 euros';
                       c('A61','A62')='< 500 euros'")
credit2$Anciennete_emploi=recode(credit2$Anciennete_emploi,
                                 "c('A71','A72')='Sans emploi ou < 1 an';
                                 'A73'='E [1-4[ ans';
                                 c('A74','A75')='E GE 4 ans'")
credit2$Situation_familiale=recode(credit2$Situation_familiale,
                                   "'A91'='Homme divorce/separe';
                                   'A92'='Femme divorcee/separee/mariee';
                                   c('A93','A94')='Homme celibataire/marie/veuf';
                                   'A95'='Femme celibataire'")
credit2$Garanties=recode(credit2$Garanties,"'A103'='Avec garant';
                         else='Sans garant'")
credit2$Biens=recode(credit2$Biens,"'A121'='Immobilier';
                     'A124'='Aucun bien';else='Non immobilier'")
credit2$Autres_credits=recode(credit2$Autres_credits,
                              "'A143'='Aucun credit exterieur';
                              else='Credit exterieurs'")
credit2$Statut_domicile=recode(credit2$Statut_domicile,
                               "'A152'='Proprietaire';
                               else='Non proprietaire'")

credit2$Duree_credit=cut(credit$Duree_credit,c(0,15,36,Inf))

credit2$Age=relevel(cut(credit$Age,c(0,25,Inf)),ref="(25,Inf]")

summary(credit2)

train=credit2[id,]
valid=credit2[-id,]
```

##Modele logit retenu
```{r}
#Modele final
logit=glm(Cible~Comptes+Historique_credit+Duree_credit+Age+Epargne+Garanties+
            Autres_credits,data=train,family=binomial(link="logit"))

summary(logit)
```

```{r}
valid$logit=predict(logit,newdata=valid,type="response")

library(ROCR)
pred=prediction(valid$logit,valid$Cible,label.ordering = c(0,1))
performance(pred,"auc")@y.values[[1]]

#Kolmogorov-Smirnov

plot.ecdf((valid$logit[valid$Cible==0]),main="Fonction de repartition du score",
          col="blue",pch=16)
plot.ecdf((valid$logit[valid$Cible==1]),
          col="red",pch=17,add=T)
legend("bottomright",c("Score=0","Score=1"),pch=c(16,17),
       col=c("blue","red"),lwd=1)

perf=performance(pred,"tpr","fpr")
max(perf@y.values[[1]]-perf@x.values[[1]])

#Maximum sensibilite + specificite
ks=perf@y.values[[1]]-perf@x.values[[1]]
(seuil=pred@cutoffs[[1]][which.max(ks)])
segments(seuil,1-perf@y.values[[1]][which.max(ks)],seuil,
         1-perf@x.values[[1]][which.max(ks)],col="black",lty=3)
```

```{r}
#Fonction de density du score

plot(density(valid$logit[valid$Cible==0]),main="Fonction de densite du score",
     col="blue",xlim=c(-0.2,1.1),ylim=c(0,3),lwd=2)
lines(density(valid$logit[valid$Cible==1]),col="red",lty=3,lwd=2)
legend("topright",c("Score=0","Score=1"),
       lty=c(1,3),col=c("blue","red"),lwd=2)
abline(v=seuil,col="grey")

plot(logit~Cible,data=valid)
```

##Grille de score

```{r}
VARIABLE=c("",gsub("[0-9]","",names(unlist(logit$xlevels))))
MODALITE=c("",as.character(unlist(logit$xlevels)))
names=data.frame(VARIABLE,MODALITE,NOMVAR=c("(Intercept)",paste(VARIABLE,MODALITE,
                                                                sep="")[-1]))

#Recuperation des coefficients du modele
regression=data.frame(NOMVAR=names(coefficients(logit)),
                      COEF=as.numeric(coefficients(logit)))

#Merge des deux data frames
param=merge(names,regression,all.x=TRUE)[-1]
param$COEF[is.na(param$COEF)]=0

#Min max et poids total
mini=aggregate(data.frame(min=param$COEF),by=list(VARIABLE=param$VARIABLE),min)
maxi=aggregate(data.frame(max=param$COEF),by=list(VARIABLE=param$VARIABLE),max)
total=merge(mini,maxi)
total$diff=total$max-total$min
poids_total=sum(total$diff)

grille=merge(param,mini,all.x=TRUE)
grille$delta=grille$COEF-grille$min
grille$POIDS=round(100*grille$delta/poids_total)
grille[which(VARIABLE!=""),c("VARIABLE","MODALITE","POIDS")]
grille[order(grille$VARIABLE,grille$MODALITE)[which(VARIABLE!="")],
       c("VARIABLE","MODALITE","POIDS")]
```

##Determination des seuils de score
```{r}
credit2$logit=predict(logit,newdata=credit2,type="response")
q=quantile(credit2$logit,seq(0,1,by=0.05))
qscore=cut(credit2$logit,q)
tab=table(qscore,credit2$Cible)
ti=prop.table(tab,1)[,2]
barplot(as.numeric(ti),col=gray(0:length(ti)/length(ti)),
        names.arg=names(ti),ylab="Taux impayes",ylim=c(0,1),
        cex.names=0.8,las=3)
abline(v=c(7.3,18.1),col="red")

#Verification
library(car)
zscore=recode(credit2$logit,"lo:0.117='Faible';
              0.117:0.486='Moyen';0.486:hi='Fort'")
table(zscore)
tab=table(zscore,credit2$Cible)
prop.table(tab,1)

# rm(logit)
# decoup(credit2,logit,Cible,nbmod=3,h=1,k=0,pAUC=0.8)
```

##Courbe ROC et courbe de lift

```{r}
#Courbe de ROC
valid$logit=predict(logit,newdata=valid,type="response")
pred=prediction(valid$logit,valid$Cible,label.ordering=c(0,1))
roc=performance(pred,"tpr","fpr")
plot(roc,main="Courbe de ROC")
segments(0,0,1,1,lty=3)
```

```{r}
#Courbe de lift
lift=performance(pred,"tpr","rpp")
plot(roc,main="Courbe de lift")
segments(0,0,prop.table(table(credit$Cible))[2],1,lty=3)
segments(prop.table(table(credit$Cible))[2],1,1,1,lty=3)

#Autre courbe de lift
lift=performance(pred,"lift","rpp")
plot(lift,main="Courbe de lift")
```

##Modele probit

```{r}
probit=glm(Cible~Comptes+Historique_credit+Duree_credit+
             Age+Epargne+Garanties+Autres_credits,
           data=train,family=binomial(probit))

summary(probit)

valid$probit=predict(probit,newdata=valid,type="response")
pred=prediction(valid$probit,valid$Cible,label.ordering = c(0,1))
performance(pred,"auc")@y.values[[1]]

logit$coefficients/probit$coefficients

```

#Regression logistique penalisee ridge

```{r}
library(glmnet)
x=model.matrix(~.-1,data=train[,! names(train) %in% c("Cible","Cle")])
y=train[,"Cible"]

set.seed(235)
cvfit=cv.glmnet(x,y,alpha=0,family="binomial",type="auc",nlambda=100)
cvfit$lambda[1] #plus petit lambda annulant tous les coefficients
cvfit$lambda[99] #lambda precedent divise par 10000
cvfit$lambda.min #lambda donnant le plus petit taux d'erruer
```

##Representation graphique

```{r}
plot(cvfit)
abline(h=cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)])
abline(v=log(cvfit$lambda.min),col="blue",lty=2)
```

```{r}
fit=glmnet(x,y,alpha=0,family="binomial",
           lambda=seq(cvfit$lambda[1],cvfit$lambda[99],length=10000),
           standardize=TRUE)

plot(fit,xvar="lambda",label="T")
```

##Validation

```{r}
xt=model.matrix(~.-1,data=valid[,! names(valid) %in% c("Cible","Cle","logit","probit")])
yt=valid[,"Cible"]
ytpred=predict(fit,newx=xt,type="response")

#ROC
library(ROCR)
roc=function(x){
  performance(prediction(ytpred[,x],yt),"auc")@y.values[[1]]
}
ptm=proc.time()
vauc=Vectorize(roc)(1:length(fit$lambda))
proc.time()-ptm

#Pararellisation
library(snow)
clus=makeCluster(4)
ptm=proc.time()
clusterExport(clus,c('performance','prediction','ytpred','yt'))
vauc=parSapply(clus,1:length(fit$lambda),'roc')
proc.time()-ptm
stopCluster(clus)

#Identification du meilleur modele
which.max(vauc)

fit$lambda[which.max(vauc)]
vauc[which.max(vauc)]

plot(vauc~log(fit$lambda),lty=2,cex=0.5,pch=16)
abline(v=log(fit$lambda[which.max(vauc)]),col="black",lty=2)
abline(h=0.7806,col="black",lty=3)

tail(log(fit$lambda)[which(vauc>=0.7806)])
tail(fit$lambda[which(vauc>=0.7806)])
```

##Affinement de la recherche du meilleur modele

```{r}
ridge=glmnet(x,y,alpha=0,family="binomial",
             lambda=seq(2,1,-0.0001),standardize=T)
ytpred=predict(ridge,newx=xt,type="response")
vauc=Vectorize(roc)(1:length(ridge$lambda))

vauc[which.max(vauc)]
ridge$lambda[which.max(vauc)]
log(ridge$lambda[which.max(vauc)])

plot(vauc~log(ridge$lambda),lty=2,cex=0.5,pch=16)
abline(h=vauc[which.max(vauc)],col='black',lty=2)
```

##Modele final
```{r}
xt=model.matrix(~.-1,data=credit2[,!names(credit2) %in% c("Cible","Cle","logit","probit")])
yt=credit2[,"Cible"]
ytpred=predict(ridge,newx=xt,type="response",
               s=ridge$lambda[which.max(vauc)])
performance(prediction(ytpred,yt),"auc")@y.values[[1]]

ytpred=predict(ridge,newx=xt,type="response",
               s=1.5)
performance(prediction(ytpred,yt),"auc")@y.values[[1]]

options(scipen=99)
coef(ridge,s=1.5)

```

```{r}
plot(fit,xvar="lambda",label="T")
abline(v=log(1.5),col='black',lty=2)
```

##Grille de score

```{r}
niveaux=Vectorize(levels)(train[,!names(train) %in% c("Cible","Cle")])
niveaux$Taux_effort=""
niveaux$Anciennete_domicile=""
niveaux$Nb_credits=""

VARIABLE=c("",gsub("[0-9]","",names(unlist(niveaux))))
MODALITE=c("",as.character(unlist(niveaux)))
names=data.frame(VARIABLE,MODALITE,NOMVAR=c("(Intercept)",
                                            paste(VARIABLE,MODALITE,sep="")[-1]))
coef=ridge$beta[,which(ridge$lambda==1.5)]
regression=data.frame(NOMVAR=names(coef),
                      COEF=as.numeric(coef))
param=merge(names,regression,al.x=TRUE)[-1]
param$COEF[is.na(param$COEF)]=0
#Calcul du poids total pour normalisation
mini=aggregate(data.frame(min=param$COEF),by=list(VARIABLE=param$VARIABLE),min)
maxi=aggregate(data.frame(max=param$COEF),by=list(VARIABLE=param$VARIABLE),max)
total=merge(mini,maxi)

total$min[total$min==total$max]=0
total$diff=abs(total$max-total$min)
poids_total=sum(total$diff)
grille=merge(param,mini,all.x=TRUE)
grille$delta=grille$COEF-grille$min

grille$delta[grille$VARIABLE=="Anciennete_domicile"]=abs(max(train$Anciennete_domicile)*    grille$COEF[grille$VARIABLE=="Anciennete_domicile"])

grille$delta[grille$VARIABLE=="Nb_credits"]=abs(max(train$Nb_credits)*    grille$COEF[grille$VARIABLE=="Nb_credits"])

grille$delta[grille$VARIABLE=="Taux_effort"]=abs(max(train$Taux_effort)*    grille$COEF[grille$VARIABLE=="Taux_effort"])
grille$POIDS=round((100*grille$delta)/poids_total)
grille[which(grille$VARIABLE!="" & grille$VARIABLE!="Cible"),
       c("VARIABLE","MODALITE","POIDS")]


```

#test
